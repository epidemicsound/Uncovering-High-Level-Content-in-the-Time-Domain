Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------
/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/oriol_colome_font_epidemicsound_/Master-Thesis/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
  | Name    | Type      | Params
--------------------------------------
0 | encoder | SampleCNN | 2.4 M
--------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.737     Total estimated model params size (MB)


Sanity Checking DataLoader 0:   0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]





