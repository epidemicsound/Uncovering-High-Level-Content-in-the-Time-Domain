Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------
/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/oriol_colome_font_epidemicsound_/Master-Thesis/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
  | Name    | Type      | Params
--------------------------------------
0 | encoder | SampleCNN | 2.4 M
--------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.737     Total estimated model params size (MB)


Sanity Checking DataLoader 0:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]


Epoch 0:  12%|██████████▍                                                                            | 3/25 [00:21<02:37,  7.14s/it, v_num=d35c]
Traceback (most recent call last):
  File "/home/oriol_colome_font_epidemicsound_/Master-Thesis/train_msd.py", line 122, in <module>
    trainer.fit(model, train_loader, validation_loader)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 520, in fit
    call._call_and_handle_interrupt(
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 92, in launch
    return function(*args, **kwargs)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 559, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 935, in _run
    results = self._run_stage()
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 978, in _run_stage
    self.fit_loop.run()
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 189, in advance
    batch = next(data_fetcher)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 136, in __next__
    self._fetch_next_batch(self.dataloader_iter)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 150, in _fetch_next_batch
    batch = next(iterator)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 264, in __next__
    out = next(self._iterator)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 52, in __next__
    out[i] = next(self.iterators[i])
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1313, in _next_data
    return self._process_data(data)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/envs/master_thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/oriol_colome_font_epidemicsound_/Master-Thesis/dataset_msd.py", line 83, in __getitem__
    frame_offset = np.random.randint(0, metadata.num_frames - num_frames)
  File "mtrand.pyx", line 748, in numpy.random.mtrand.RandomState.randint
  File "_bounded_integers.pyx", line 1247, in numpy.random._bounded_integers._rand_int64
ValueError: high <= 0