{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Audio Data Augmentation\n",
        "\n",
        "**Author**: [Moto Hira](moto@meta.com)_\n",
        "\n",
        "``torchaudio`` provides a variety of ways to augment audio data.\n",
        "\n",
        "In this tutorial, we look into a way to apply effects, filters,\n",
        "RIR (room impulse response) and codecs.\n",
        "\n",
        "At the end, we synthesize noisy speech over phone from clean speech.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation\n",
        "\n",
        "First, we import the modules and download the audio assets we use in this tutorial.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(os.getcwd())\n",
        "print(os.listdir(\"../../../datasets/GTZAN/gtzan_genre/genres/blues\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = '../../../datasets/GTZAN/gtzan_genre/genres/'\n",
        "genres = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
        "\n",
        "test_list = []\n",
        "for genre in genres:\n",
        "    song = random.choice(os.listdir(root + genre))\n",
        "    audio, sr = torchaudio.load(os.path.join(root, genre, song))\n",
        "    test_list.append(['test_audio_' + str(genre), audio, sr])\n",
        "\n",
        "print(test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applying effects and filtering\n",
        "\n",
        ":py:func:`torchaudio.sox_effects` allows for directly applying filters similar to\n",
        "those available in ``sox`` to Tensor objects and file object audio sources.\n",
        "\n",
        "There are two functions for this:\n",
        "\n",
        "-  :py:func:`torchaudio.sox_effects.apply_effects_tensor` for applying effects\n",
        "   to Tensor.\n",
        "-  :py:func:`torchaudio.sox_effects.apply_effects_file` for applying effects to\n",
        "   other audio sources.\n",
        "\n",
        "Both functions accept effect definitions in the form\n",
        "``List[List[str]]``.\n",
        "This is mostly consistent with how ``sox`` command works, but one caveat is\n",
        "that ``sox`` adds some effects automatically, whereas ``torchaudio``â€™s\n",
        "implementation does not.\n",
        "\n",
        "For the list of available effects, please refer to [the sox\n",
        "documentation](http://sox.sourceforge.net/sox.html)_.\n",
        "\n",
        "**Tip** If you need to load and resample your audio data on the fly,\n",
        "then you can use :py:func:`torchaudio.sox_effects.apply_effects_file`\n",
        "with effect ``\"rate\"``.\n",
        "\n",
        "**Note** :py:func:`torchaudio.sox_effects.apply_effects_file` accepts a\n",
        "file-like object or path-like object.\n",
        "Similar to :py:func:`torchaudio.load`, when the audio format cannot be\n",
        "inferred from either the file extension or header, you can provide\n",
        "argument ``format`` to specify the format of the audio source.\n",
        "\n",
        "**Note** This process is not differentiable.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torchaudio.sox_effects.effect_names()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://sox.sourceforge.net/sox.html#EFFECTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "effects_to_keep = ['allpass',\n",
        " 'band',\n",
        " 'bandpass',\n",
        " 'bandreject',\n",
        " 'bass',\n",
        " 'bend',\n",
        " 'chorus',\n",
        " 'compand',\n",
        " 'contrast',\n",
        " 'delay',\n",
        " 'dither',\n",
        " 'divide',\n",
        " 'earwax',\n",
        " 'echo',\n",
        " 'echos',\n",
        " 'equalizer',\n",
        " 'flanger',\n",
        " 'highpass',\n",
        " 'hilbert',\n",
        " 'loudness',\n",
        " 'lowpass',\n",
        " 'mcompand',\n",
        " 'norm',\n",
        " 'overdrive',\n",
        " 'phaser',\n",
        " 'pitch',\n",
        " 'reverb',\n",
        " 'speed',\n",
        " 'stretch',\n",
        " 'tempo',\n",
        " 'treble',\n",
        " 'tremolo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for audio in test_list:\n",
        "    print(audio[0])\n",
        "    Audio(audio[1], rate=audio[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None):\n",
        "    waveform = waveform.numpy()\n",
        "\n",
        "    num_channels, num_frames = waveform.shape\n",
        "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "    figure, axes = plt.subplots(num_channels, 1)\n",
        "    if num_channels == 1:\n",
        "        axes = [axes]\n",
        "    for c in range(num_channels):\n",
        "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
        "        axes[c].grid(True)\n",
        "        if num_channels > 1:\n",
        "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
        "        if xlim:\n",
        "            axes[c].set_xlim(xlim)\n",
        "    figure.suptitle(title)\n",
        "    plt.show(block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(test_list)):\n",
        "    plot_waveform(test_list[i][1], test_list[i][2], title=str(test_list[i][0]), xlim=None)\n",
        "    play_audio(test_list[i][1], test_list[i][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trans_list = []\n",
        "for audio in test_list:\n",
        "    # Define effects\n",
        "    effects = [\n",
        "        [\"lowpass\", \"-1\", \"1000\"],  # apply single-pole lowpass filter\n",
        "        [\"speed\", \"1.5\"],  # reduce the speed\n",
        "        # This only changes sample rate, so it is necessary to\n",
        "        # add `rate` effect with original sample rate after this.\n",
        "        [\"rate\", f\"{audio[2]}\"],\n",
        "        [\"reverb\", \"-w\"],  # Reverbration\n",
        "    ]\n",
        "\n",
        "    # Apply effects\n",
        "    y_trans, sr_trans = torchaudio.sox_effects.apply_effects_tensor(audio[1], audio[2], effects)\n",
        "    trans_list.append([audio[0] + '_trans', y_trans, sr_trans])\n",
        "    print(y_trans.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Effects applied:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(trans_list)):\n",
        "    plot_waveform(trans_list[i][1], trans_list[i][2], title=str(trans_list[i][0]), xlim=None)\n",
        "    play_audio(trans_list[i][1], trans_list[i][2])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
