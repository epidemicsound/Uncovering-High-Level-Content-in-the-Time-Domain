{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIU_7VBXaUf0"
      },
      "source": [
        "# WavAugment walkthrough\n",
        "\n",
        "In this colab document, we will go through some basic functionality that WavAugment provides. We will\n",
        "*  install some required packages,\n",
        "*  show how to apply simple augmentations on a speech sequence,\n",
        "*  how to combine and randomize them,\n",
        "*  discuss some useful considerations and limitations.\n",
        "\n",
        "Our overall target is cover most of the things that we found useful for deep self-supervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mo7_1UqHvY8"
      },
      "source": [
        "## Applying simple and useful augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pi_pXDzMtiY"
      },
      "source": [
        "Let's import everything we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxvULQLAQ7QE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "import os\n",
        "import random\n",
        "import augment\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG2UlEnWH8SM"
      },
      "source": [
        "Let's load the snippet of the speech and listen to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(os.getcwd())\n",
        "print(os.listdir(\"../../../datasets/GTZAN/gtzan_genre/genres/blues\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = '../../../datasets/GTZAN/gtzan_genre/genres/'\n",
        "genres = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
        "\n",
        "test_list = []\n",
        "for genre in genres:\n",
        "    song = random.choice(os.listdir(root + genre))\n",
        "    audio, sr = torchaudio.load(os.path.join(root, genre, song))\n",
        "    test_list.append(['test_audio_' + str(genre), audio, sr])\n",
        "\n",
        "print(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "eWq35hN4S6Ga",
        "outputId": "c08070da-191f-4ecf-d8de-a15d6b45b8ce"
      },
      "outputs": [],
      "source": [
        "for audio in test_list:\n",
        "    print(audio[0])\n",
        "    Audio(audio[1], rate=audio[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None):\n",
        "    waveform = waveform.numpy()\n",
        "\n",
        "    num_channels, num_frames = waveform.shape\n",
        "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "    figure, axes = plt.subplots(num_channels, 1)\n",
        "    if num_channels == 1:\n",
        "        axes = [axes]\n",
        "    for c in range(num_channels):\n",
        "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
        "        axes[c].grid(True)\n",
        "        if num_channels > 1:\n",
        "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
        "        if xlim:\n",
        "            axes[c].set_xlim(xlim)\n",
        "    figure.suptitle(title)\n",
        "    plt.show(block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(test_list)):\n",
        "    #plot_waveform(test_list[i][1], test_list[i][2], title=str(test_list[i][0]), xlim=None)\n",
        "    play_audio(test_list[i][1], test_list[i][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVylbGf6Jnwm"
      },
      "source": [
        "Similarly to `sox`, the central entity of WavAugment is a sequence of effects, `augment.EffectChain`. As the name indicates, we can create various combinations of audio effects by chaining them together. This chain can be empty and do nothing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp2DDt_aKOmB"
      },
      "outputs": [],
      "source": [
        "empty_chain = augment.EffectChain()\n",
        "for x in test_list:\n",
        "    y = empty_chain.apply(x[1], src_info={'rate': x[2]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNF4g8oeKR4N"
      },
      "source": [
        "or can contain one or more effects. Let us create a chain that applies a clipping effect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPBVUBfgKOoq"
      },
      "outputs": [],
      "source": [
        "clip_chain = augment.EffectChain().clip(0.6)\n",
        "for x in test_list:\n",
        "    y = clip_chain.apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOwRcQbdNHHa"
      },
      "source": [
        "We can append effects one after another, just like below where we put `rate` transformer after the `pitch` one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "S7UgybVYT2St",
        "outputId": "1cffa2f1-38ed-4a7c-d17a-2b33f6261ba9"
      },
      "outputs": [],
      "source": [
        "for x in test_list:\n",
        "    y = augment.EffectChain().pitch(1200).rate(x[2]).apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO94kTuRNkIb"
      },
      "source": [
        "Here, we have lowered the pitch of the voice by 2 tones: -200 indicates that we'll go lower by 200 cents of the tone.\n",
        "\n",
        "Similarly, we can go up by the same amount:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM4C2NjwOzIj"
      },
      "source": [
        "Why do we to put `rate` after pitch? At the moment, WavAugment's `pitch` provides a somewhat thin wrapper around the corresponding effect of `libsox` [*]. Internally, `libsox` would represent change in the pitch as combination of `tempo` and `rate` effects; so for the time being we need to change the rate back manually.\n",
        "\n",
        "[*] This is subject to change in the future, as we re-iterate on the library.\n",
        "\n",
        "\n",
        "Another effect that we found useful is `reverb`. The reverberations that are provided by `sox` are specified by three parameters: reverberance, dumping factor, and room size. Check how it sounds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "9ukrSPWwV2CA",
        "outputId": "e6ed531c-c882-4a09-8cc1-2f1485fc1ece"
      },
      "outputs": [],
      "source": [
        "for x in test_list:\n",
        "    y = augment.EffectChain().reverb(100, 50, 100).channels(1).apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrv4Oh1iByLw"
      },
      "source": [
        "Again, we need to add the `channels` effect due to pecularities of `libsox`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNyureVXB_MO"
      },
      "source": [
        "What else can we do? Another effect that is often used in the literature, is replacing a small span of audio with silence. We can do that, too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "pkTAgqtdV608",
        "outputId": "d68a7e91-15cf-4c0e-a39e-c5ee9f9e42cc"
      },
      "outputs": [],
      "source": [
        "for x in test_list:\n",
        "    y = augment.EffectChain().time_dropout(max_seconds=1.0).apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQVCcqO5DyIt"
      },
      "source": [
        "Applying additive noise is a bit more involved, as we need a database of noise, such as [MUSAN](https://www.openslr.org/17/). For the sake of this small tutorial, we will use generated uniform noise. The additive noise effect consumes a Callable that returns the noise to be added: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "HH0IznpTEabP",
        "outputId": "ac4cbd2c-121d-46be-e94c-770dcd3b4076"
      },
      "outputs": [],
      "source": [
        "for x in test_list:\n",
        "    noise_generator = lambda: torch.zeros_like(x[1]).uniform_()\n",
        "    y = augment.EffectChain().additive_noise(noise_generator, snr=5).apply(x[1], src_info={'rate': sr})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbxjQNnyFiDv"
      },
      "source": [
        "WavAugment does not normalize the inputs, neither noise nor the input tensor, this needs to be kept in mind.\n",
        "\n",
        "In terms of sox effects, bandreject can be implemented as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2TFrxPEWEhFJ",
        "outputId": "80681f39-3ed2-4d52-9a56-1d514fd8212c"
      },
      "outputs": [],
      "source": [
        "for x in test_list:\n",
        "    y = augment.EffectChain().sinc('-a', '120', '500-100').apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    print(x[0])\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVMV5dmYGY5z"
      },
      "source": [
        "## Randomization & Combining\n",
        "\n",
        "So in data augmentation we typically want to randomize the applied augmentation and/or its strength. All effects in WavAugment take a Callable as any of its parameters, which provides a way randomize the applied effect. For instance, we can randomize pitch as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcdmSin_L7JD"
      },
      "source": [
        "If an effect has several parameters, we can replace all or some of them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "MBsvIIddLwZc",
        "outputId": "9f6a9932-a2c2-4fb2-a2f3-b2512b53d2ac"
      },
      "outputs": [],
      "source": [
        "random_room_size = lambda: np.random.randint(0, 101)\n",
        "random_reverb = augment.EffectChain().reverb(50, 50, random_room_size).channels(1)\n",
        "\n",
        "for x in test_list:\n",
        "    y = random_reverb.apply(x[1], src_info={'rate': x[2]})\n",
        "    #plot_waveform(y, x[2], title=str(x[0]), xlim=None)\n",
        "    play_audio(y, x[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8hw1ND5M1b8"
      },
      "source": [
        "We can easily stack augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "cjEAWYTDM0FP",
        "outputId": "fef6d882-ea24-496e-f73f-6af15fb683d6"
      },
      "outputs": [],
      "source": [
        "combination = augment.EffectChain() \\\n",
        "  .pitch(\"-q\", random_pitch_shift).rate(sr) \\\n",
        "  .reverb(50, 50, random_room_size).channels(1) \\\n",
        "  .additive_noise(noise_generator, snr=15) \\\n",
        "  .time_dropout(max_seconds=1.0)\n",
        "y = combination.apply(x, src_info={'rate': sr}, target_info={'rate': sr})\n",
        "Audio(y, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7znSmVlqPfa2"
      },
      "source": [
        "## Discussion & Limitations\n",
        "\n",
        "*  Currently, all augmentations are non-batched (and done on CPU). Hence, it's a good idea to apply them inside a parallelized dataloader (see our example [example](https://github.com/facebookresearch/WavAugment/blob/master/examples/python/librispeech_selfsupervised.py)),\n",
        "* In some corner cases, `pitch` augmentation within libsox might return `NaN`. If this happens, it can be useful to handle this case (as we do [here](https://github.com/facebookresearch/WavAugment/blob/master/examples/python/librispeech_selfsupervised.py#L118)),\n",
        "* To interpret what sox-based effects do and which parameters they take, please consult the sox [documentation](http://sox.sourceforge.net/sox.html). All effects apart from additive noise, time dropout, and clipping are based on sox,\n",
        "* The full list of 64 supported effects is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z-4H_nIeSVfD",
        "outputId": "41c0def9-bffe-4e54-c7a3-bb9113868082"
      },
      "outputs": [],
      "source": [
        "augment.EffectChain.KNOWN_EFFECTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "WavAugment walkthrough.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
